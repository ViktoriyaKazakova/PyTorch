{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Приложен ноутбук, в котором реализованы функции для генирации из большого\n",
    "датасета меньшая его копия. Вам нужно перенести функции из этого ноутбука в\n",
    "класс датасет и сделать следующее:\n",
    "a. Сгенерировать меньший датасет из 8-10 классов движения\n",
    "b. Обучить уже существующую модель (предварительно проанализировав\n",
    "какие параметры модели нужно изменить)\n",
    "c. Изменить модель: посмотреть зависимость от количества LSTM модулей\n",
    "в нашей модели\n",
    "d. Сгенерировать другой датасет с меньшим количеством “кадров” в серии\n",
    "и сравнить улучшилось или ухудшилось качество предсказания.\n",
    "Провести несколько таких итераций, дать свою оценку уменьшению и\n",
    "увеличению кадров, назвать оптимальное, на ваш взгляд, их количество.\n",
    "Желательно сделать так, чтобы длина последовательности\n",
    "передавалась как атрибут класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/nturgb+d_skeletons/\"\n",
    "broken_files_path = \"D:/NTU_RGBD_samples_with_missing_skeletons.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_classes = sorted([8, 10, 22, 23, 27, 21, 5, 29]) \n",
    "LABELS = {x: training_classes[x] for x in range(len(training_classes))}\n",
    "training_cameras = [1, 2, 3] \n",
    "num_joint = 25\n",
    "max_frame = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_path, broken_files_path=None, training_classes=None,\n",
    "                 num_joint = 25, max_frame = 300, transform=None):\n",
    "        \n",
    "        \n",
    "        def read_data(data_path, broken_files_path):\n",
    "            labels = []\n",
    "            files = []\n",
    "            action_classes = {}\n",
    "            counter = 0\n",
    "            files_counter = {}\n",
    "            with open(broken_files_path, 'r') as f:\n",
    "                broken_files = f.read().split(\"\\n\")\n",
    "\n",
    "            raw_files = os.listdir(data_path)\n",
    "            num_frames = 0\n",
    "\n",
    "            for filename in raw_files:\n",
    "                if filename not in broken_files:\n",
    "                    action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n",
    "                    subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n",
    "                    camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n",
    "                    if action_class in training_classes and camera_id in training_cameras: \n",
    "                        if action_class in action_classes:\n",
    "                            if files_counter[action_class] < 120:\n",
    "                                files.append([filename,action_classes[action_class]])\n",
    "                                files_counter[action_class] = files_counter[action_class] + 1\n",
    "                        else:\n",
    "                            action_classes.update({action_class : counter})\n",
    "                            files_counter.update({action_class : 1})\n",
    "                            counter+=1\n",
    "                            files.append([filename,action_classes[action_class]])\n",
    "            print(\"action classes: \", action_classes)\n",
    "            print(\"action files: \", files_counter)\n",
    "\n",
    "            return files, action_classes\n",
    "        \n",
    "        def read_skeleton_filter(file):\n",
    "            with open(file, 'r') as f:\n",
    "                skeleton_sequence = {}\n",
    "                skeleton_sequence['numFrame'] = int(f.readline())\n",
    "                skeleton_sequence['frameInfo'] = []\n",
    "                for t in range(skeleton_sequence['numFrame']):\n",
    "                    frame_info = {}\n",
    "                    frame_info['numBody'] = int(f.readline())\n",
    "                    frame_info['bodyInfo'] = []\n",
    "\n",
    "                    for m in range(frame_info['numBody']):\n",
    "                        body_info = {}\n",
    "                        body_info_key = [\n",
    "                            'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
    "                            'handLeftState', 'handRightConfidence', 'handRightState',\n",
    "                            'isResticted', 'leanX', 'leanY', 'trackingState'\n",
    "                        ]\n",
    "                        body_info = {\n",
    "                            k: float(v)\n",
    "                            for k, v in zip(body_info_key, f.readline().split())\n",
    "                        }\n",
    "                        body_info['numJoint'] = int(f.readline())\n",
    "                        body_info['jointInfo'] = []\n",
    "                        for v in range(body_info['numJoint']):\n",
    "                            joint_info_key = [\n",
    "                                'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
    "                                'orientationW', 'orientationX', 'orientationY',\n",
    "                                'orientationZ', 'trackingState'\n",
    "                            ]\n",
    "                            joint_info = {\n",
    "                                k: float(v)\n",
    "                                for k, v in zip(joint_info_key, f.readline().split())\n",
    "                            }\n",
    "                            body_info['jointInfo'].append(joint_info)\n",
    "                        frame_info['bodyInfo'].append(body_info)\n",
    "                    skeleton_sequence['frameInfo'].append(frame_info)\n",
    "\n",
    "            return skeleton_sequence\n",
    "        \n",
    "        def read_xyz(file, max_body=1, num_joint=25):\n",
    "            seq_info = read_skeleton_filter(file)\n",
    "            data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n",
    "            for n, f in enumerate(seq_info['frameInfo']):\n",
    "                for m, b in enumerate(f['bodyInfo']):\n",
    "                    for j, v in enumerate(b['jointInfo']):\n",
    "                        if m < max_body and j < num_joint:\n",
    "                            data[m, n, j, :] = [v['x'], v['y'], v['z']]\n",
    "\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "            return data\n",
    "        \n",
    "        \n",
    "        def create_coords_blocks(test_file, chonk_len = 45):   \n",
    "            frame_counter = 0\n",
    "            new_labels = []\n",
    "            new_frames = []\n",
    "            blocks = []\n",
    "\n",
    "            test_frames = read_xyz(data_path + test_file[0])[0]\n",
    "            label = test_file[1]\n",
    "            slice_len = chonk_len * int(len(test_frames)/chonk_len)\n",
    "\n",
    "\n",
    "            for index in range(len(test_frames[:slice_len])):\n",
    "                frame_counter += 1\n",
    "                new_frames.append(test_frames[index].flatten())\n",
    "                if frame_counter == chonk_len:\n",
    "                    frame_counter = 0\n",
    "                    blocks.append(np.array(new_frames))\n",
    "                    new_labels = new_labels + [label]\n",
    "                    new_frames = []\n",
    "\n",
    "\n",
    "            return blocks, new_labels\n",
    "        \n",
    "        \n",
    "        working_files_with_labels, action_classes = read_data(data_path, broken_files_path)\n",
    "        \n",
    "        data = []\n",
    "        labels = []\n",
    "        ##########################################################################\n",
    "        numbers = {x: 0 for x in range(len(action_classes))}  #####\n",
    "        ##################################################################\n",
    "        for file in working_files_with_labels:\n",
    "            frames_blocks, label = create_coords_blocks(file)\n",
    "            if label != [] and numbers[label[0]] <= 150:\n",
    "                numbers[label[0]] = numbers[label[0]] + len(label)\n",
    "                data = data + frames_blocks\n",
    "                labels = labels + label\n",
    "        data_np = np.asarray(data)\n",
    "        labels_np = np.asarray(labels)\n",
    "\n",
    "        data_sq = data_np.reshape(len(data_np), -1)\n",
    "        data = pd.DataFrame(data_sq)\n",
    "        labels = pd.DataFrame(labels_np)\n",
    "        data['labels'] = labels\n",
    "        \n",
    "\n",
    "        self.data = data\n",
    "        self.labels = data['labels'].astype('float32')\n",
    "        self.transform = transform\n",
    "        \n",
    "           \n",
    "    def __len__(self):\n",
    "         return len(self.data)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = np.asarray(self.data.iloc[idx,:-1]).reshape(45,75)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform != None:\n",
    "            item = transform(item)\n",
    "        return (item, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action classes:  {5: 0, 10: 1, 21: 2, 23: 3, 27: 4, 29: 5, 8: 6, 22: 7}\n",
      "action files:  {5: 120, 10: 120, 21: 120, 23: 120, 27: 120, 29: 120, 8: 120, 22: 120}\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(data_path=data_path, broken_files_path=broken_files_path, \n",
    "                           training_classes=training_classes,num_joint = 25, \n",
    "                           max_frame = 300, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d3105acab271>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.70\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.30\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Prog\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[1;34m(dataset, lengths, generator)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;31m# Cannot verify that dataset is Sized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.70*len(dataset)),int(0.30*len(dataset))])\n",
    "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И вот тут все встало( Вроде ничего такого не сделано, просто функции из Data preparation оформлены в класс. Поиск по ошибке ничего не выдает кроме нескольких репо на гитхабе с такой же ошибкой. Возможно архив с датасетом в диск со свободными 100 ГБ распаковывается не полностью, выдает ошибку что недостаточно места. Распакованый он занимает 5,72 ГБ. Если дело в этом скажите пожалуйста как это можно поправить, памяти как будто достаточно но выходит ошибка и видимо не все файлы распаковываются. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
